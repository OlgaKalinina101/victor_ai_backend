import asyncio
import json
import traceback
from typing import List, Any, Optional, Dict, Union, AsyncGenerator

import aiohttp

from infrastructure.llm.usage import track_usage, track_usage_stream
from infrastructure.logging.logger import setup_logger
from settings import settings


class LLMClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å LLM API."""

    def __init__(self, account_id: str = "test_user", mode: str = "advanced"):
        self.mode = mode
        self.account_id = account_id
        self.logger = setup_logger("llm_client")
        self.mode_config = {
            "creative": {
                "model": "grok-3-beta",
                "url": "https://api.x.ai/v1/chat/completions",
                "bearer": settings.XAI_API_KEY,
                "temperature": 0.5,
                "max_tokens": 1500,
                "provider": "xai"
            },
            "advanced": {
                "model": "gpt-4o",
                "url": "https://api.openai.com/v1/chat/completions",
                "bearer": settings.OPENAI_API_KEY,
                "temperature": 0.5,
                "max_tokens": 1500,
                "provider": "openai"
            },
            "foundation": {
                "model": "deepseek-chat",
                "url": "https://api.deepseek.com/v1/chat/completions",
                "bearer": settings.DEEPSEEK_API_KEY,
                "temperature": 0.5,
                "max_tokens": 1500,
                "provider": "deepseek"
            }
        }
        if mode not in self.mode_config:
            self.logger.error(f"[ERROR] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {mode}")
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {mode}")
        self.model_name = self.mode_config[mode]["model"]
        self.provider = self.mode_config[mode]["provider"]
        self.timeout = aiohttp.ClientTimeout(total=120)
        self.max_retries = 3

    async def get_response(self,
                      system_prompt: str,
                      context_prompt: str,
                      message_history: Optional[List[str]] = None,
                      new_message: Optional[str] = None,
                      temperature: float = 0.5,
                      top_p: Optional[float] = None,
                      max_tokens: int = 1500,
                      stream: bool = False) -> Union[str, AsyncGenerator[str, None]]:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.

        Args:
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç.
            context_prompt: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç.
            message_history: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π.
            new_message: –ù–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
            top_p: –ü–∞—Ä–∞–º–µ—Ç—Ä top-p (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω).
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤.
            stream: –†–µ–∂–∏–º —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ (–Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏).

        Returns:
            str: –û—Ç–≤–µ—Ç LLM –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ.
        """
        self.logger.info(f"[INFO] –ó–∞–ø—É—Å–∫ LLM –≤ —Ä–µ–∂–∏–º–µ {self.mode}, stream={stream}")

        try:
            messages = self._build_messages(system_prompt, context_prompt, message_history, new_message)
            json_payload = self._build_payload(temperature, top_p, max_tokens, stream)
            json_payload["messages"] = messages

            if stream:
                return self._send_request_stream(json_payload)  # ‚Üê generator
            else:
                response = await self._send_request(json_payload)  # ‚Üê dict
                return response["assistant_response"]

        except Exception as e:
            self.logger.exception(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ LLM: {e}")
            if stream:
                async def error_generator():
                    yield "–ö–∞–∂–µ—Ç—Å—è, —É –Ω–∞—Å —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ —Å API –∏–ª–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º..."

                return error_generator()
            else:
                return "–ö–∞–∂–µ—Ç—Å—è, —É –Ω–∞—Å —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ —Å API –∏–ª–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º..."

    async def get_response_stream(
            self,
            system_prompt: str,
            context_prompt: str,
            message_history: List[str],
            new_message: str,
            temperature: float = 0.5,
            top_p: Optional[float] = None,
            max_tokens: int = 1500
    ) -> AsyncGenerator[str, None]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–∏–º —á–∞–Ω–∫–æ–≤."""
        self.logger.info(f"[INFO] –ó–∞–ø—É—Å–∫ LLM –≤ —Ä–µ–∂–∏–º–µ {self.mode}, stream=True")
        try:
            messages = self._build_messages(system_prompt, context_prompt, message_history, new_message)
            json_payload = self._build_payload(temperature, top_p, max_tokens, stream=True)
            json_payload["messages"] = messages

            async for chunk in self._send_request_stream(json_payload):
                yield chunk

        except Exception as e:
            self.logger.exception(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ LLM: {e}")
            yield "–ö–∞–∂–µ—Ç—Å—è, —É –Ω–∞—Å —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ —Å API –∏–ª–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º..."

    def _build_messages(self, system_prompt: str, context_prompt: str, message_history: List[str], new_message: str) -> \
    List[Dict[str, str]]:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è API."""
        self.logger.debug("[DEBUG] –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π")
        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": context_prompt}
            ]
            # –ò—Å—Ç–æ—Ä–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
            if message_history:
                parsed_history = []
                for line in message_history:
                    if line.startswith("user:"):
                        parsed_history.append({"role": "user", "content": line[5:].strip()})
                    elif line.startswith("assistant:"):
                        parsed_history.append({"role": "assistant", "content": line[10:].strip()})
                    else:
                        self.logger.warning(f"[WARNING] –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏ –≤ –∏—Å—Ç–æ—Ä–∏–∏: {line}")
                messages.extend(parsed_history)

            # –ù–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            if new_message:
                messages.append({"role": "user", "content": new_message})

            self.logger.debug(f"[DEBUG] –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {messages}")
            return messages
        except Exception as e:
            self.logger.error(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π: {e}")
            raise

    def _build_payload(self, temperature: float, top_p: Optional[float], max_tokens: int, stream: bool) -> Dict[
        str, Any]:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç JSON-–øayload –¥–ª—è API-–∑–∞–ø—Ä–æ—Å–∞."""
        self.logger.debug("[DEBUG] –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ payload")
        try:
            cfg = self.mode_config[self.mode]
            json_payload = {
                "model": cfg["model"],
                "messages": None,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ _send_request
                "max_tokens": max_tokens,
                "temperature": temperature if temperature is not None else cfg["temperature"],
                "stream": stream
            }
            if top_p is not None:
                json_payload["top_p"] = top_p
            return json_payload
        except Exception as e:
            self.logger.error(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ payload: {e}")
            raise

    @track_usage()
    async def _send_request(self, json_payload: Dict[str, Any]) -> dict:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM API —Å —Ä–µ—Ç—Ä–∞—è–º–∏."""
        self.logger.debug("[DEBUG] –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM API")
        cfg = self.mode_config[self.mode]
        error_msg = "–Ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ –∑–∞–¥—É–º–∞–ª—Å—è, —á—Ç–æ —Å–ª–æ–º–∞–ª API... üòè –î–∞–≤–∞–π —Å–Ω–∏–∑–∏–º –≥—Ä–∞–¥—É—Å?"

        for retry in range(self.max_retries):
            try:
                async with aiohttp.ClientSession() as session:
                    self.logger.info(f"[DEBUG] –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {cfg['url']}, –ø–æ–ø—ã—Ç–∫–∞ {retry + 1}/{self.max_retries}")
                    response = await session.post(
                        cfg["url"],
                        json={**json_payload, "messages": json_payload["messages"]},
                        headers={"Authorization": f"Bearer {cfg['bearer']}"},
                        timeout=self.timeout
                    )

                    self.logger.info(f"[DEBUG] –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞ API: {response.status}")

                    if response.status != 200:
                        error_body = await response.text()
                        self.logger.error(f"[ERROR] –ü–æ–ª—É—á–µ–Ω —Å—Ç–∞—Ç—É—Å {response.status}, —Ç–µ–ª–æ: {error_body}")
                        return {
                            "assistant_response": error_msg,
                            "usage": {}
                        }

                    response.raise_for_status()
                    data = await response.json()
                    self.logger.debug(f"[DEBUG] –û—Ç–≤–µ—Ç API: {data}")

                    if not data.get("choices"):
                        self.logger.error("[ERROR] –í –æ—Ç–≤–µ—Ç–µ API –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç choices")
                        return {
                            "assistant_response": error_msg,
                            "usage": {}
                        }

                    choice = data["choices"][0]
                    if "message" not in choice or "content" not in choice["message"]:
                        self.logger.error("[ERROR] –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç message –∏–ª–∏ content")
                        return {
                            "assistant_response": error_msg,
                            "usage": {}
                        }

                    assistant_response = choice["message"]["content"]
                    if assistant_response is None:
                        self.logger.error("[ERROR] –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç–≤–µ—Ç–∞ —Ä–∞–≤–Ω–æ None")
                        return {
                            "assistant_response": error_msg,
                            "usage": {}
                        }

                    self.logger.info(f"[DEBUG] –†–µ–∑—É–ª—å—Ç–∞—Ç API: {assistant_response[:100]}...")
                    return {
                        "assistant_response": assistant_response.strip(),
                        "usage": data.get("usage", {})
                    }

            except aiohttp.ClientResponseError as e:
                self.logger.error(f"[ERROR] ClientResponseError: {e}")
                error_body = await e.response.text() if hasattr(e, "response") else "No response body"
                self.logger.error(f"[DEBUG] –¢–µ–ª–æ –æ—Ç–≤–µ—Ç–∞: {error_body}")
                if e.status == 429:
                    self.logger.info(f"[DEBUG] –õ–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {2 ** retry} —Å–µ–∫—É–Ω–¥")
                    await asyncio.sleep(2 ** retry)
                    continue
                return {
                    "assistant_response": error_msg,
                    "usage": {}
                }

            except asyncio.TimeoutError as e:
                self.logger.error(f"[ERROR] TimeoutError: {e}")
                self.logger.debug(f"[DEBUG] Traceback: {traceback.format_exc()}")
                self.logger.info(f"[DEBUG] –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {2 ** retry} —Å–µ–∫—É–Ω–¥")
                await asyncio.sleep(2 ** retry)
                continue

            except Exception as e:
                self.logger.error(f"[ERROR] –û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API: {e}")
                self.logger.debug(f"[DEBUG] Traceback: {traceback.format_exc()}")
                return {
                    "assistant_response": error_msg,
                    "usage": {}
                }

        self.logger.error(f"[ERROR] –í—Å–µ {self.max_retries} –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å")
        return {
            "assistant_response": "–ö–∞–∂–µ—Ç—Å—è, —É –Ω–∞—Å —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ —Å API –∏–ª–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º...",
            "usage": {}
        }

    @track_usage_stream()
    async def _send_request_stream(self, json_payload: Dict[str, Any]) -> AsyncGenerator[Union[str, dict], None]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM API –≤ —Ä–µ–∂–∏–º–µ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞."""
        self.logger.debug("[DEBUG] –û—Ç–ø—Ä–∞–≤–∫–∞ streaming-–∑–∞–ø—Ä–æ—Å–∞ –∫ LLM API")
        cfg = self.mode_config[self.mode]
        error_msg = "–Ø –Ω–∞—Å—Ç–æ–ª—å–∫–æ –∑–∞–¥—É–º–∞–ª—Å—è, —á—Ç–æ —Å–ª–æ–º–∞–ª API... üòè –î–∞–≤–∞–π —Å–Ω–∏–∑–∏–º –≥—Ä–∞–¥—É—Å?"
        collected_usage: dict | None = None  # ‚Üê —Å—é–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏–º usage

        for retry in range(self.max_retries):
            try:
                async with aiohttp.ClientSession() as session:
                    self.logger.info(f"[DEBUG] Streaming-–∑–∞–ø—Ä–æ—Å –∫ {cfg['url']}, –ø–æ–ø—ã—Ç–∫–∞ {retry + 1}/{self.max_retries}")

                    async with session.post(
                            cfg["url"],
                            json={**json_payload, "stream": True},  # ‚Üê —è–≤–Ω–æ –≤–∫–ª—é—á–∞–µ–º stream
                            headers={"Authorization": f"Bearer {cfg['bearer']}"},
                            timeout=self.timeout
                    ) as response:

                        if response.status != 200:
                            error_body = await response.text()
                            self.logger.error(f"[ERROR] –°—Ç–∞—Ç—É—Å {response.status}: {error_body}")
                            yield error_msg
                            return

                        # –ß–∏—Ç–∞–µ–º SSE-–ø–æ—Ç–æ–∫
                        async for line in response.content:
                            line = line.decode('utf-8').strip()

                            if not line or line == "data: [DONE]":
                                continue

                            if line.startswith("data: "):
                                try:
                                    chunk_data = json.loads(line[6:])  # —É–±–∏—Ä–∞–µ–º "data: "

                                    # === –ò–©–ï–ú USAGE ===
                                    if "usage" in chunk_data:
                                        collected_usage = chunk_data["usage"]
                                        self.logger.debug(f"[USAGE] –ù–∞–π–¥–µ–Ω–æ: {collected_usage}")
                                        # –ù–ï yield'–∏–º usage ‚Äî —Ç–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º

                                    # –ü–∞—Ä—Å–∏–º chunk (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞)
                                    if "choices" in chunk_data and chunk_data["choices"]:
                                        delta = chunk_data["choices"][0].get("delta", {})
                                        content = delta.get("content", "")
                                        if content:
                                            yield content

                                except json.JSONDecodeError as e:
                                    self.logger.warning(f"[WARN] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å chunk: {line[:100]}")
                                    continue

                            # === –ö–û–ù–ï–¶ –°–¢–†–ò–ú–ê: –û–¢–ü–†–ê–í–õ–Ø–ï–ú USAGE ===
                            if collected_usage:
                                self.logger.info(
                                    f"[USAGE] –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ —Å—Ç—Ä–∏–º: prompt={collected_usage.get('prompt_tokens')} "
                                    f"output={collected_usage.get('completion_tokens')}")
                                yield {"usage": collected_usage}

                        return  # —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª–∏ —Å—Ç—Ä–∏–º

            except aiohttp.ClientResponseError as e:
                self.logger.error(f"[ERROR] ClientResponseError: {e}")
                if e.status == 429:
                    self.logger.info(f"[DEBUG] Rate limit, –∂–¥—ë–º {2 ** retry}—Å")
                    await asyncio.sleep(2 ** retry)
                    continue
                yield error_msg
                return

            except asyncio.TimeoutError:
                self.logger.error(f"[ERROR] Timeout, –∂–¥—ë–º {2 ** retry}—Å")
                await asyncio.sleep(2 ** retry)
                continue

            except Exception as e:
                self.logger.error(f"[ERROR] –û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {e}")
                self.logger.debug(f"[DEBUG] Traceback: {traceback.format_exc()}")
                yield error_msg
                return

        self.logger.error(f"[ERROR] –í—Å–µ {self.max_retries} –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å")
        yield "–ö–∞–∂–µ—Ç—Å—è, —É –Ω–∞—Å —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ —Å API –∏–ª–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º..."

    def update_config(self, mode: str, **kwargs: Any) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞."""
        self.logger.debug(f"[DEBUG] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Ä–µ–∂–∏–º–∞ {mode}")
        try:
            if mode not in self.mode_config:
                self.logger.error(f"[ERROR] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {mode}")
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {mode}")
            self.mode_config[mode].update(kwargs)
            self.logger.info(f"[DEBUG] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è {mode} –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {kwargs}")
        except Exception as e:
            self.logger.error(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            raise




