# Victor AI - Personal AI Companion for Android
# Copyright (C) 2025-2026 Olga Kalinina

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.

from io import BytesIO
from logging import Logger
from pathlib import Path
from typing import Optional, Dict, Any

from PIL import Image

from infrastructure.logging.logger import setup_logger
from infrastructure.utils.io_utils import yaml_safe_load
from infrastructure.vision import VisionClient

# –ü—É—Ç—å –∫ –ø—Ä–æ–º–ø—Ç–∞–º Vision
PROMPTS_PATH = Path(__file__).parent / "vision_prompts.yaml"


class VisionBuilder:
    """
    –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ vision-–º–æ–¥–µ–ª—å—é:
    1) –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (photo / ui_screenshot / dialogue_screenshot),
    2) —Å—Ç—Ä–æ–∏—Ç –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π vision-context –¥–ª—è –ø–∞—Ä—Ç–Ω—ë—Ä–∞.
    """

    def __init__(
        self,
        model: str = "Qwen/Qwen3-VL-8B-Instruct:novita",
        api_url: str = "https://router.huggingface.co/v1/chat/completions",
        api_token: Optional[str] = None,
        logger: Optional[Logger] = None,
        account_id: str = None,
    ) -> None:
        self.logger = logger or setup_logger("vision_builder")

        self.client = VisionClient(
            model=model,
            api_url=api_url,
            api_token=api_token,
            logger=self.logger,
            timeout=30,
            account_id=account_id,
        )

        # –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞–¥–∏–π vision-–ø–∞–π–ø–ª–∞–π–Ω–∞
        self.prompts: Dict[str, str] = yaml_safe_load(PROMPTS_PATH, self.logger)
        self.system_prompt: str = self.prompts.get("vision_system_prompt", "")
        self.image_type_prompt_tpl: str = self.prompts.get("vision_image_type_prompt", "")
        self.vision_context_tpl: str = self.prompts.get("vision_context_prompt", "")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∂–∞—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.max_image_size = 1024  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ –¥–ª–∏–Ω–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ
        self.jpeg_quality = 85  # –ö–∞—á–µ—Å—Ç–≤–æ JPEG —Å–∂–∞—Ç–∏—è

    # ---------- —Å–∂–∞—Ç–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ----------

    def compress_image(self, image_bytes: bytes, mime_type: str = "image/png") -> bytes:
        """
        –°–∂–∏–º–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è API.
        
        Args:
            image_bytes: –ò—Å—Ö–æ–¥–Ω—ã–µ –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            mime_type: MIME-—Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            –°–∂–∞—Ç—ã–µ –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        try:
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img = Image.open(BytesIO(image_bytes))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º RGBA –≤ RGB –¥–ª—è JPEG
            if img.mode in ('RGBA', 'LA', 'P'):
                background = Image.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                img = background
            
            original_size = img.size
            original_bytes = len(image_bytes)
            
            # –†–µ—Å–∞–π–∑–∏–º –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ
            if max(img.size) > self.max_image_size:
                # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
                ratio = self.max_image_size / max(img.size)
                new_size = tuple(int(dim * ratio) for dim in img.size)
                img = img.resize(new_size, Image.Resampling.LANCZOS)
                self.logger.info(f"[COMPRESS] –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–æ —Å {original_size} –Ω–∞ {new_size}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JPEG —Å —É–º–µ—Ä–µ–Ω–Ω—ã–º —Å–∂–∞—Ç–∏–µ–º
            output = BytesIO()
            img.save(output, format='JPEG', quality=self.jpeg_quality, optimize=True)
            compressed_bytes = output.getvalue()
            
            compressed_size = len(compressed_bytes)
            compression_ratio = (1 - compressed_size / original_bytes) * 100
            
            self.logger.info(
                f"[COMPRESS] –°–∂–∞—Ç–∏–µ: {original_bytes} bytes -> {compressed_size} bytes "
                f"({compression_ratio:.1f}% —ç–∫–æ–Ω–æ–º–∏–∏)"
            )
            
            return compressed_bytes
            
        except Exception as e:
            self.logger.warning(f"[COMPRESS] –û—à–∏–±–∫–∞ —Å–∂–∞—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª")
            return image_bytes

    # ---------- –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Ç–æ—Ä–æ–π —Å—Ç–∞–¥–∏–∏ (–∫–æ–Ω—Ç–µ–∫—Å—Ç) ----------

    def build_visual_context_prompt(self, image_type: str, user_input: str) -> str:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Ç–æ—Ä–æ–π —Å—Ç–∞–¥–∏–∏ (–ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è),
        –∏—Å—Ö–æ–¥—è –∏–∑ —Ç–∏–ø–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        """

        type_to_prompt_key = {
            "photo": "vision_photo_context_prompt",
            "ui_screenshot": "vision_ui_screenshot_context_prompt",
            "dialogue_screenshot": "vision_dialogue_screenshot_context_prompt",
        }

        prompt_key = type_to_prompt_key.get(image_type, "vision_default_context_prompt")
        template = self.prompts.get(prompt_key, "")

        if not template:
            # –§–æ–ª–±—ç–∫ –Ω–∞ —Å–ª—É—á–∞–π –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            return ""

        return template.format(user_input=user_input)

    # ---------- —Å—Ç–∞–¥–∏—è 1: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º image_type ----------

    async def _detect_image_type(
        self,
        text: str,
        image_bytes: bytes,
        mime_type: str,
    ) -> str:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç vision-–º–æ–¥–µ–ª—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–Ω–æ –∏–∑: 'photo', 'ui_screenshot', 'dialogue_screenshot' –∏–ª–∏ ''.
        """

        if not self.image_type_prompt_tpl:
            self.logger.warning("–ù–µ –∑–∞–¥–∞–Ω vision_image_type_prompt –≤ –ø—Ä–æ–º–ø—Ç–∞—Ö")
            return ""

        prompt = self.image_type_prompt_tpl.format(user_input=text)

        result: Dict[str, Any] = await self.client.analyze_json(
            image=image_bytes,
            prompt=prompt,
            system_prompt=self.system_prompt,
            mime_type=mime_type,
            temperature=0.0,
        )

        image_type = result.get("image_type", "")

        if not image_type:
            self.logger.warning(
                "–û—Ç–≤–µ—Ç vision-–º–æ–¥–µ–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç 'image_type'. result=%s",
                result,
            )

        return image_type

    # ---------- —Å—Ç–∞–¥–∏—è 2: —Å—Ç—Ä–æ–∏–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π vision_context ----------

    async def _build_vision_context(
        self,
        image_type: str,
        text: str,
        image_bytes: bytes,
        mime_type: str,
    ) -> str:
        """
        –°—Ç—Ä–æ–∏—Ç –∫–æ—Ä–æ—Ç–∫–∏–π vision-context –¥–ª—è Victor AI –ø–æ —Ç–∏–ø—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        """

        context_prompt = self.build_visual_context_prompt(
            image_type=image_type,
            user_input=text,
        )

        result: Dict[str, Any] = await self.client.analyze_json(
            image=image_bytes,
            prompt=context_prompt,
            system_prompt=self.system_prompt,
            mime_type=mime_type,
            temperature=0.0,
        )

        content: str = result.get("content", "") or ""

        if not content:
            self.logger.info(
                "Vision-–∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç 'content', –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π vision_context"
            )
            return ""

        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π —à–∞–±–ª–æ–Ω –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ vision_context ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ,
        # –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º content –∫–∞–∫ –µ—Å—Ç—å.
        if self.vision_context_tpl:
            try:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                if image_type == "photo":
                    image_type_text = "—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π"
                elif image_type in ["ui_screenshot", "dialogue_screenshot"]:
                    image_type_text = "—Å–∫—Ä–∏–Ω—à–æ—Ç–æ–º"
                else:
                    image_type_text = "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º"
                
                vision_context = self.vision_context_tpl.format(
                    image_type_text = image_type_text,
                    content=content
                )
            except Exception:
                self.logger.exception(
                    "–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è vision_context_tpl, "
                    "–≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—ã—Ä–æ–π content"
                )
                vision_context = content
        else:
            vision_context = content

        return vision_context

    # ---------- –ø—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ ----------

    async def analyze_screenshot(
        self,
        text: str,
        image_bytes: bytes,
        mime_type: str = "image/png",
    ) -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç vision-context –¥–ª—è –¥–∏–∞–ª–æ–≥–∞.

        Args:
            text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏—à—ë–ª –≤–º–µ—Å—Ç–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º (—Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è).
            image_bytes: –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ñ–æ—Ç–æ / —Å–∫—Ä–∏–Ω—à–æ—Ç).
            mime_type: MIME-—Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

        Returns:
            –°—Ç—Ä–æ–∫–∞ –¥–ª—è –ø–æ–¥–º–µ—à–∏–≤–∞–Ω–∏—è –≤ context_prompt (–Ω–∞–ø—Ä–∏–º–µ—Ä:
            "–§–∞–∫—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞: ...", "–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ü–µ–Ω—ã: ...").
            –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ ‚Äî –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ.
        """

        self.logger.info("–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è: %s", text[:100])

        try:
            # üî• –°–ñ–ò–ú–ê–ï–ú –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ API
            compressed_image_bytes = self.compress_image(image_bytes, mime_type)
            
            image_type = await self._detect_image_type(
                text=text,
                image_bytes=compressed_image_bytes,
                mime_type="image/jpeg",  # –ü–æ—Å–ª–µ —Å–∂–∞—Ç–∏—è –≤—Å–µ–≥–¥–∞ JPEG
            )

            vision_context = await self._build_vision_context(
                image_type=image_type,
                text=text,
                image_bytes=compressed_image_bytes,
                mime_type="image/jpeg",  # –ü–æ—Å–ª–µ —Å–∂–∞—Ç–∏—è –≤—Å–µ–≥–¥–∞ JPEG
            )

            self.logger.info("Vision context: %s", vision_context or "<empty>")
            return vision_context

        except Exception as e:
            self.logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: %s", e)
            raise



